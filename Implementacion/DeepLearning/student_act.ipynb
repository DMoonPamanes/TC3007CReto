{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StudentID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>ParentalEducation</th>\n",
       "      <th>StudyTimeWeekly</th>\n",
       "      <th>Absences</th>\n",
       "      <th>Tutoring</th>\n",
       "      <th>ParentalSupport</th>\n",
       "      <th>Extracurricular</th>\n",
       "      <th>Sports</th>\n",
       "      <th>Music</th>\n",
       "      <th>Volunteering</th>\n",
       "      <th>GPA</th>\n",
       "      <th>GradeClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>19.833723</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.929196</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.408756</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.042915</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1003</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4.210570</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.112602</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1004</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10.028829</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.054218</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1005</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4.672495</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.288061</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   StudentID  Age  Gender  Ethnicity  ParentalEducation  StudyTimeWeekly  \\\n",
       "0       1001   17       1          0                  2        19.833723   \n",
       "1       1002   18       0          0                  1        15.408756   \n",
       "2       1003   15       0          2                  3         4.210570   \n",
       "3       1004   17       1          0                  3        10.028829   \n",
       "4       1005   17       1          0                  2         4.672495   \n",
       "\n",
       "   Absences  Tutoring  ParentalSupport  Extracurricular  Sports  Music  \\\n",
       "0         7         1                2                0       0      1   \n",
       "1         0         0                1                0       0      0   \n",
       "2        26         0                2                0       0      0   \n",
       "3        14         0                3                1       0      0   \n",
       "4        17         1                3                0       0      0   \n",
       "\n",
       "   Volunteering       GPA  GradeClass  \n",
       "0             0  2.929196         2.0  \n",
       "1             0  3.042915         1.0  \n",
       "2             0  0.112602         4.0  \n",
       "3             0  2.054218         3.0  \n",
       "4             0  1.288061         4.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv('Student_performance_data _.csv')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "96/96 [==============================] - 1s 3ms/step - loss: 0.7997 - mean_absolute_error: 0.6924 - val_loss: 0.2077 - val_mean_absolute_error: 0.3717\n",
      "Epoch 2/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.1341 - mean_absolute_error: 0.2886 - val_loss: 0.0939 - val_mean_absolute_error: 0.2509\n",
      "Epoch 3/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0903 - mean_absolute_error: 0.2392 - val_loss: 0.0754 - val_mean_absolute_error: 0.2263\n",
      "Epoch 4/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0743 - mean_absolute_error: 0.2190 - val_loss: 0.0673 - val_mean_absolute_error: 0.2117\n",
      "Epoch 5/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0643 - mean_absolute_error: 0.2046 - val_loss: 0.0618 - val_mean_absolute_error: 0.2018\n",
      "Epoch 6/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0576 - mean_absolute_error: 0.1942 - val_loss: 0.0567 - val_mean_absolute_error: 0.1933\n",
      "Epoch 7/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0529 - mean_absolute_error: 0.1861 - val_loss: 0.0545 - val_mean_absolute_error: 0.1898\n",
      "Epoch 8/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0502 - mean_absolute_error: 0.1820 - val_loss: 0.0535 - val_mean_absolute_error: 0.1877\n",
      "Epoch 9/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0479 - mean_absolute_error: 0.1775 - val_loss: 0.0517 - val_mean_absolute_error: 0.1828\n",
      "Epoch 10/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0458 - mean_absolute_error: 0.1733 - val_loss: 0.0514 - val_mean_absolute_error: 0.1837\n",
      "Epoch 11/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0441 - mean_absolute_error: 0.1699 - val_loss: 0.0512 - val_mean_absolute_error: 0.1819\n",
      "Epoch 12/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0422 - mean_absolute_error: 0.1661 - val_loss: 0.0504 - val_mean_absolute_error: 0.1803\n",
      "Epoch 13/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0416 - mean_absolute_error: 0.1650 - val_loss: 0.0479 - val_mean_absolute_error: 0.1755\n",
      "Epoch 14/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0411 - mean_absolute_error: 0.1641 - val_loss: 0.0481 - val_mean_absolute_error: 0.1768\n",
      "Epoch 15/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0397 - mean_absolute_error: 0.1607 - val_loss: 0.0477 - val_mean_absolute_error: 0.1758\n",
      "Epoch 16/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0386 - mean_absolute_error: 0.1571 - val_loss: 0.0473 - val_mean_absolute_error: 0.1750\n",
      "Epoch 17/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0386 - mean_absolute_error: 0.1585 - val_loss: 0.0475 - val_mean_absolute_error: 0.1753\n",
      "Epoch 18/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0377 - mean_absolute_error: 0.1558 - val_loss: 0.0479 - val_mean_absolute_error: 0.1762\n",
      "Epoch 19/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0372 - mean_absolute_error: 0.1558 - val_loss: 0.0502 - val_mean_absolute_error: 0.1786\n",
      "Epoch 20/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0364 - mean_absolute_error: 0.1535 - val_loss: 0.0470 - val_mean_absolute_error: 0.1736\n",
      "Epoch 21/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0359 - mean_absolute_error: 0.1528 - val_loss: 0.0475 - val_mean_absolute_error: 0.1755\n",
      "Epoch 22/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0355 - mean_absolute_error: 0.1517 - val_loss: 0.0475 - val_mean_absolute_error: 0.1758\n",
      "Epoch 23/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0350 - mean_absolute_error: 0.1515 - val_loss: 0.0459 - val_mean_absolute_error: 0.1721\n",
      "Epoch 24/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0354 - mean_absolute_error: 0.1526 - val_loss: 0.0467 - val_mean_absolute_error: 0.1740\n",
      "Epoch 25/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0340 - mean_absolute_error: 0.1497 - val_loss: 0.0500 - val_mean_absolute_error: 0.1782\n",
      "Epoch 26/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0340 - mean_absolute_error: 0.1492 - val_loss: 0.0465 - val_mean_absolute_error: 0.1737\n",
      "Epoch 27/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0338 - mean_absolute_error: 0.1472 - val_loss: 0.0464 - val_mean_absolute_error: 0.1744\n",
      "Epoch 28/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0331 - mean_absolute_error: 0.1464 - val_loss: 0.0489 - val_mean_absolute_error: 0.1766\n",
      "Epoch 29/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0331 - mean_absolute_error: 0.1467 - val_loss: 0.0486 - val_mean_absolute_error: 0.1774\n",
      "Epoch 30/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0324 - mean_absolute_error: 0.1453 - val_loss: 0.0469 - val_mean_absolute_error: 0.1739\n",
      "Epoch 31/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0320 - mean_absolute_error: 0.1434 - val_loss: 0.0465 - val_mean_absolute_error: 0.1739\n",
      "Epoch 32/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0318 - mean_absolute_error: 0.1439 - val_loss: 0.0501 - val_mean_absolute_error: 0.1792\n",
      "Epoch 33/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0316 - mean_absolute_error: 0.1436 - val_loss: 0.0489 - val_mean_absolute_error: 0.1753\n",
      "Epoch 34/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0319 - mean_absolute_error: 0.1439 - val_loss: 0.0474 - val_mean_absolute_error: 0.1753\n",
      "Epoch 35/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0309 - mean_absolute_error: 0.1413 - val_loss: 0.0465 - val_mean_absolute_error: 0.1731\n",
      "Epoch 36/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0310 - mean_absolute_error: 0.1411 - val_loss: 0.0470 - val_mean_absolute_error: 0.1746\n",
      "Epoch 37/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0305 - mean_absolute_error: 0.1405 - val_loss: 0.0489 - val_mean_absolute_error: 0.1770\n",
      "Epoch 38/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0303 - mean_absolute_error: 0.1399 - val_loss: 0.0469 - val_mean_absolute_error: 0.1752\n",
      "Epoch 39/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0304 - mean_absolute_error: 0.1399 - val_loss: 0.0514 - val_mean_absolute_error: 0.1816\n",
      "Epoch 40/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0299 - mean_absolute_error: 0.1386 - val_loss: 0.0475 - val_mean_absolute_error: 0.1762\n",
      "Epoch 41/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0298 - mean_absolute_error: 0.1388 - val_loss: 0.0488 - val_mean_absolute_error: 0.1766\n",
      "Epoch 42/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0292 - mean_absolute_error: 0.1368 - val_loss: 0.0519 - val_mean_absolute_error: 0.1821\n",
      "Epoch 43/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0304 - mean_absolute_error: 0.1405 - val_loss: 0.0521 - val_mean_absolute_error: 0.1836\n",
      "Epoch 44/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0295 - mean_absolute_error: 0.1375 - val_loss: 0.0481 - val_mean_absolute_error: 0.1771\n",
      "Epoch 45/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0289 - mean_absolute_error: 0.1358 - val_loss: 0.0464 - val_mean_absolute_error: 0.1754\n",
      "Epoch 46/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0291 - mean_absolute_error: 0.1372 - val_loss: 0.0472 - val_mean_absolute_error: 0.1742\n",
      "Epoch 47/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0287 - mean_absolute_error: 0.1360 - val_loss: 0.0484 - val_mean_absolute_error: 0.1778\n",
      "Epoch 48/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0285 - mean_absolute_error: 0.1350 - val_loss: 0.0482 - val_mean_absolute_error: 0.1754\n",
      "Epoch 49/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0282 - mean_absolute_error: 0.1348 - val_loss: 0.0456 - val_mean_absolute_error: 0.1737\n",
      "Epoch 50/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0279 - mean_absolute_error: 0.1322 - val_loss: 0.0498 - val_mean_absolute_error: 0.1765\n",
      "Test Loss: 0.051232073456048965\n",
      "Test Mean Absolute Error: 0.17820331454277039\n"
     ]
    }
   ],
   "source": [
    "X = data.drop(columns=['StudentID', 'GPA', 'GradeClass'])  \n",
    "y = data['GPA']  \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),  \n",
    "    Dense(1)  \n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=16, validation_split=0.2, verbose=1)\n",
    "\n",
    "test_loss, test_mae = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Mean Absolute Error:\", test_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "96/96 [==============================] - 2s 5ms/step - loss: 1.0904 - mean_absolute_error: 0.7418 - val_loss: 0.1688 - val_mean_absolute_error: 0.3277\n",
      "Epoch 2/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.1218 - mean_absolute_error: 0.2802 - val_loss: 0.1213 - val_mean_absolute_error: 0.2767\n",
      "Epoch 3/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0900 - mean_absolute_error: 0.2421 - val_loss: 0.0963 - val_mean_absolute_error: 0.2450\n",
      "Epoch 4/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0718 - mean_absolute_error: 0.2146 - val_loss: 0.0855 - val_mean_absolute_error: 0.2302\n",
      "Epoch 5/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0620 - mean_absolute_error: 0.2004 - val_loss: 0.0785 - val_mean_absolute_error: 0.2209\n",
      "Epoch 6/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0551 - mean_absolute_error: 0.1887 - val_loss: 0.0771 - val_mean_absolute_error: 0.2199\n",
      "Epoch 7/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0505 - mean_absolute_error: 0.1809 - val_loss: 0.0699 - val_mean_absolute_error: 0.2063\n",
      "Epoch 8/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0468 - mean_absolute_error: 0.1734 - val_loss: 0.0683 - val_mean_absolute_error: 0.2065\n",
      "Epoch 9/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0424 - mean_absolute_error: 0.1662 - val_loss: 0.0761 - val_mean_absolute_error: 0.2133\n",
      "Epoch 10/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0415 - mean_absolute_error: 0.1639 - val_loss: 0.0679 - val_mean_absolute_error: 0.2034\n",
      "Epoch 11/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0396 - mean_absolute_error: 0.1608 - val_loss: 0.0694 - val_mean_absolute_error: 0.2057\n",
      "Epoch 12/50\n",
      "96/96 [==============================] - 0s 5ms/step - loss: 0.0389 - mean_absolute_error: 0.1594 - val_loss: 0.0720 - val_mean_absolute_error: 0.2092\n",
      "Epoch 13/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0368 - mean_absolute_error: 0.1533 - val_loss: 0.0644 - val_mean_absolute_error: 0.2018\n",
      "Epoch 14/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0353 - mean_absolute_error: 0.1513 - val_loss: 0.0639 - val_mean_absolute_error: 0.2005\n",
      "Epoch 15/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0345 - mean_absolute_error: 0.1487 - val_loss: 0.0713 - val_mean_absolute_error: 0.2134\n",
      "Epoch 16/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0352 - mean_absolute_error: 0.1511 - val_loss: 0.0605 - val_mean_absolute_error: 0.1946\n",
      "Epoch 17/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0336 - mean_absolute_error: 0.1481 - val_loss: 0.0604 - val_mean_absolute_error: 0.1939\n",
      "Epoch 18/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0318 - mean_absolute_error: 0.1432 - val_loss: 0.0667 - val_mean_absolute_error: 0.2029\n",
      "Epoch 19/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0319 - mean_absolute_error: 0.1424 - val_loss: 0.0593 - val_mean_absolute_error: 0.1933\n",
      "Epoch 20/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0295 - mean_absolute_error: 0.1375 - val_loss: 0.0635 - val_mean_absolute_error: 0.2013\n",
      "Epoch 21/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0301 - mean_absolute_error: 0.1415 - val_loss: 0.0602 - val_mean_absolute_error: 0.1960\n",
      "Epoch 22/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0286 - mean_absolute_error: 0.1357 - val_loss: 0.0650 - val_mean_absolute_error: 0.2006\n",
      "Epoch 23/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0294 - mean_absolute_error: 0.1381 - val_loss: 0.0585 - val_mean_absolute_error: 0.1926\n",
      "Epoch 24/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0267 - mean_absolute_error: 0.1305 - val_loss: 0.0575 - val_mean_absolute_error: 0.1904\n",
      "Epoch 25/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0269 - mean_absolute_error: 0.1306 - val_loss: 0.0575 - val_mean_absolute_error: 0.1910\n",
      "Epoch 26/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0269 - mean_absolute_error: 0.1305 - val_loss: 0.0596 - val_mean_absolute_error: 0.1930\n",
      "Epoch 27/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0257 - mean_absolute_error: 0.1267 - val_loss: 0.0636 - val_mean_absolute_error: 0.2005\n",
      "Epoch 28/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0252 - mean_absolute_error: 0.1269 - val_loss: 0.0587 - val_mean_absolute_error: 0.1937\n",
      "Epoch 29/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0246 - mean_absolute_error: 0.1256 - val_loss: 0.0581 - val_mean_absolute_error: 0.1902\n",
      "Epoch 30/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0252 - mean_absolute_error: 0.1263 - val_loss: 0.0605 - val_mean_absolute_error: 0.1951\n",
      "Epoch 31/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0241 - mean_absolute_error: 0.1245 - val_loss: 0.0580 - val_mean_absolute_error: 0.1912\n",
      "Epoch 32/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0241 - mean_absolute_error: 0.1237 - val_loss: 0.0603 - val_mean_absolute_error: 0.1958\n",
      "Epoch 33/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0223 - mean_absolute_error: 0.1197 - val_loss: 0.0599 - val_mean_absolute_error: 0.1946\n",
      "Epoch 34/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0230 - mean_absolute_error: 0.1204 - val_loss: 0.0593 - val_mean_absolute_error: 0.1937\n",
      "Epoch 35/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0227 - mean_absolute_error: 0.1196 - val_loss: 0.0607 - val_mean_absolute_error: 0.1947\n",
      "Epoch 36/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0234 - mean_absolute_error: 0.1220 - val_loss: 0.0626 - val_mean_absolute_error: 0.1985\n",
      "Epoch 37/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0216 - mean_absolute_error: 0.1160 - val_loss: 0.0598 - val_mean_absolute_error: 0.1930\n",
      "Epoch 38/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0214 - mean_absolute_error: 0.1155 - val_loss: 0.0617 - val_mean_absolute_error: 0.1952\n",
      "Epoch 39/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0207 - mean_absolute_error: 0.1142 - val_loss: 0.0616 - val_mean_absolute_error: 0.1994\n",
      "Epoch 40/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0211 - mean_absolute_error: 0.1141 - val_loss: 0.0596 - val_mean_absolute_error: 0.1944\n",
      "Epoch 41/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0194 - mean_absolute_error: 0.1102 - val_loss: 0.0635 - val_mean_absolute_error: 0.2003\n",
      "Epoch 42/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0193 - mean_absolute_error: 0.1097 - val_loss: 0.0653 - val_mean_absolute_error: 0.2000\n",
      "Epoch 43/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0192 - mean_absolute_error: 0.1083 - val_loss: 0.0614 - val_mean_absolute_error: 0.1972\n",
      "Epoch 44/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0193 - mean_absolute_error: 0.1096 - val_loss: 0.0640 - val_mean_absolute_error: 0.2006\n",
      "Epoch 45/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0198 - mean_absolute_error: 0.1114 - val_loss: 0.0642 - val_mean_absolute_error: 0.1994\n",
      "Epoch 46/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0188 - mean_absolute_error: 0.1077 - val_loss: 0.0657 - val_mean_absolute_error: 0.2020\n",
      "Epoch 47/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0189 - mean_absolute_error: 0.1087 - val_loss: 0.0606 - val_mean_absolute_error: 0.1972\n",
      "Epoch 48/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0181 - mean_absolute_error: 0.1046 - val_loss: 0.0685 - val_mean_absolute_error: 0.2055\n",
      "Epoch 49/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0171 - mean_absolute_error: 0.1017 - val_loss: 0.0660 - val_mean_absolute_error: 0.2038\n",
      "Epoch 50/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0184 - mean_absolute_error: 0.1058 - val_loss: 0.0633 - val_mean_absolute_error: 0.2002\n",
      "Test Loss: 0.06516163051128387\n",
      "Test Mean Absolute Error: 0.1989322006702423\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1) \n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=16, validation_split=0.2, verbose=1)\n",
    "\n",
    "test_loss, test_mae = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Mean Absolute Error:\", test_mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "96/96 [==============================] - 2s 5ms/step - loss: 2.2435 - mean_absolute_error: 1.2124 - val_loss: 0.4689 - val_mean_absolute_error: 0.5709\n",
      "Epoch 2/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.9138 - mean_absolute_error: 0.7509 - val_loss: 0.2909 - val_mean_absolute_error: 0.4580\n",
      "Epoch 3/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.7213 - mean_absolute_error: 0.6599 - val_loss: 0.3039 - val_mean_absolute_error: 0.4766\n",
      "Epoch 4/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6346 - mean_absolute_error: 0.6156 - val_loss: 0.1746 - val_mean_absolute_error: 0.3550\n",
      "Epoch 5/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5604 - mean_absolute_error: 0.5826 - val_loss: 0.1649 - val_mean_absolute_error: 0.3442\n",
      "Epoch 6/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.4577 - mean_absolute_error: 0.5193 - val_loss: 0.1852 - val_mean_absolute_error: 0.3695\n",
      "Epoch 7/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.4450 - mean_absolute_error: 0.5087 - val_loss: 0.2247 - val_mean_absolute_error: 0.4080\n",
      "Epoch 8/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.3935 - mean_absolute_error: 0.4784 - val_loss: 0.1259 - val_mean_absolute_error: 0.2932\n",
      "Epoch 9/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.3774 - mean_absolute_error: 0.4720 - val_loss: 0.1199 - val_mean_absolute_error: 0.2879\n",
      "Epoch 10/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.3618 - mean_absolute_error: 0.4623 - val_loss: 0.1506 - val_mean_absolute_error: 0.3293\n",
      "Epoch 11/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.3240 - mean_absolute_error: 0.4378 - val_loss: 0.1394 - val_mean_absolute_error: 0.3178\n",
      "Epoch 12/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.3421 - mean_absolute_error: 0.4446 - val_loss: 0.1389 - val_mean_absolute_error: 0.3163\n",
      "Epoch 13/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.3123 - mean_absolute_error: 0.4309 - val_loss: 0.1226 - val_mean_absolute_error: 0.2951\n",
      "Epoch 14/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.3025 - mean_absolute_error: 0.4184 - val_loss: 0.1289 - val_mean_absolute_error: 0.3039\n",
      "Epoch 15/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.2675 - mean_absolute_error: 0.3948 - val_loss: 0.1390 - val_mean_absolute_error: 0.3124\n",
      "Epoch 16/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.2617 - mean_absolute_error: 0.3885 - val_loss: 0.1065 - val_mean_absolute_error: 0.2716\n",
      "Epoch 17/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.2713 - mean_absolute_error: 0.3980 - val_loss: 0.0731 - val_mean_absolute_error: 0.2210\n",
      "Epoch 18/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.2427 - mean_absolute_error: 0.3769 - val_loss: 0.1212 - val_mean_absolute_error: 0.2901\n",
      "Epoch 19/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.2163 - mean_absolute_error: 0.3617 - val_loss: 0.0896 - val_mean_absolute_error: 0.2450\n",
      "Epoch 20/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.2362 - mean_absolute_error: 0.3707 - val_loss: 0.0992 - val_mean_absolute_error: 0.2573\n",
      "Epoch 21/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.2206 - mean_absolute_error: 0.3583 - val_loss: 0.1187 - val_mean_absolute_error: 0.2847\n",
      "Epoch 22/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.2062 - mean_absolute_error: 0.3485 - val_loss: 0.0836 - val_mean_absolute_error: 0.2335\n",
      "Epoch 23/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.2170 - mean_absolute_error: 0.3549 - val_loss: 0.1105 - val_mean_absolute_error: 0.2723\n",
      "Epoch 24/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.2012 - mean_absolute_error: 0.3431 - val_loss: 0.0900 - val_mean_absolute_error: 0.2455\n",
      "Epoch 25/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.2145 - mean_absolute_error: 0.3519 - val_loss: 0.0836 - val_mean_absolute_error: 0.2364\n",
      "Epoch 26/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.2014 - mean_absolute_error: 0.3403 - val_loss: 0.0807 - val_mean_absolute_error: 0.2307\n",
      "Epoch 27/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.1954 - mean_absolute_error: 0.3362 - val_loss: 0.0995 - val_mean_absolute_error: 0.2560\n",
      "Epoch 28/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.1901 - mean_absolute_error: 0.3303 - val_loss: 0.0588 - val_mean_absolute_error: 0.1912\n",
      "Epoch 29/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.1864 - mean_absolute_error: 0.3334 - val_loss: 0.0653 - val_mean_absolute_error: 0.2042\n",
      "Epoch 30/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.1824 - mean_absolute_error: 0.3258 - val_loss: 0.0924 - val_mean_absolute_error: 0.2461\n",
      "Epoch 31/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.1842 - mean_absolute_error: 0.3234 - val_loss: 0.0820 - val_mean_absolute_error: 0.2300\n",
      "Epoch 32/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.1715 - mean_absolute_error: 0.3206 - val_loss: 0.0960 - val_mean_absolute_error: 0.2517\n",
      "Epoch 33/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.1707 - mean_absolute_error: 0.3145 - val_loss: 0.1142 - val_mean_absolute_error: 0.2753\n",
      "Epoch 34/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.1579 - mean_absolute_error: 0.3048 - val_loss: 0.0721 - val_mean_absolute_error: 0.2158\n",
      "Epoch 35/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.1566 - mean_absolute_error: 0.3016 - val_loss: 0.0921 - val_mean_absolute_error: 0.2444\n",
      "Epoch 36/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.1584 - mean_absolute_error: 0.3018 - val_loss: 0.0683 - val_mean_absolute_error: 0.2109\n",
      "Epoch 37/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.1539 - mean_absolute_error: 0.2989 - val_loss: 0.0568 - val_mean_absolute_error: 0.1926\n",
      "Epoch 38/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.1508 - mean_absolute_error: 0.3050 - val_loss: 0.0738 - val_mean_absolute_error: 0.2177\n",
      "Epoch 39/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.1444 - mean_absolute_error: 0.2881 - val_loss: 0.0703 - val_mean_absolute_error: 0.2111\n",
      "Epoch 40/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.1507 - mean_absolute_error: 0.2996 - val_loss: 0.0813 - val_mean_absolute_error: 0.2295\n",
      "Epoch 41/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.1364 - mean_absolute_error: 0.2822 - val_loss: 0.0794 - val_mean_absolute_error: 0.2260\n",
      "Epoch 42/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.1499 - mean_absolute_error: 0.2941 - val_loss: 0.0728 - val_mean_absolute_error: 0.2156\n",
      "Epoch 43/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.1472 - mean_absolute_error: 0.2934 - val_loss: 0.0673 - val_mean_absolute_error: 0.2060\n",
      "Epoch 44/50\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1509 - mean_absolute_error: 0.2936 - val_loss: 0.0774 - val_mean_absolute_error: 0.2256\n",
      "Epoch 45/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.1425 - mean_absolute_error: 0.2864 - val_loss: 0.0790 - val_mean_absolute_error: 0.2232\n",
      "Epoch 46/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.1399 - mean_absolute_error: 0.2881 - val_loss: 0.0856 - val_mean_absolute_error: 0.2346\n",
      "Epoch 47/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.1384 - mean_absolute_error: 0.2785 - val_loss: 0.0744 - val_mean_absolute_error: 0.2194\n",
      "Epoch 48/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.1434 - mean_absolute_error: 0.2881 - val_loss: 0.1020 - val_mean_absolute_error: 0.2611\n",
      "Epoch 49/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.1333 - mean_absolute_error: 0.2773 - val_loss: 0.0739 - val_mean_absolute_error: 0.2149\n",
      "Epoch 50/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.1307 - mean_absolute_error: 0.2756 - val_loss: 0.0812 - val_mean_absolute_error: 0.2272\n",
      "Test Loss: 0.07740888744592667\n",
      "Test Mean Absolute Error: 0.22147782146930695\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.3),  \n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dropout(0.3), \n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=16, validation_split=0.2, verbose=1)\n",
    "\n",
    "test_loss, test_mae = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Mean Absolute Error:\", test_mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "96/96 [==============================] - 2s 5ms/step - loss: 4.4245 - mean_absolute_error: 1.8081 - val_loss: 4.1468 - val_mean_absolute_error: 1.8829\n",
      "Epoch 2/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 2.8291 - mean_absolute_error: 1.4342 - val_loss: 2.9451 - val_mean_absolute_error: 1.6011\n",
      "Epoch 3/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.7500 - mean_absolute_error: 1.0986 - val_loss: 1.5851 - val_mean_absolute_error: 1.1514\n",
      "Epoch 4/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.1496 - mean_absolute_error: 0.8709 - val_loss: 0.7866 - val_mean_absolute_error: 0.7797\n",
      "Epoch 5/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.8155 - mean_absolute_error: 0.7080 - val_loss: 0.4528 - val_mean_absolute_error: 0.5731\n",
      "Epoch 6/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.6759 - mean_absolute_error: 0.6352 - val_loss: 0.3181 - val_mean_absolute_error: 0.4738\n",
      "Epoch 7/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5662 - mean_absolute_error: 0.5936 - val_loss: 0.2503 - val_mean_absolute_error: 0.4172\n",
      "Epoch 8/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.5052 - mean_absolute_error: 0.5612 - val_loss: 0.2050 - val_mean_absolute_error: 0.3760\n",
      "Epoch 9/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.4599 - mean_absolute_error: 0.5486 - val_loss: 0.1847 - val_mean_absolute_error: 0.3582\n",
      "Epoch 10/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.4012 - mean_absolute_error: 0.5075 - val_loss: 0.1726 - val_mean_absolute_error: 0.3467\n",
      "Epoch 11/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.4019 - mean_absolute_error: 0.5010 - val_loss: 0.1411 - val_mean_absolute_error: 0.3085\n",
      "Epoch 12/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.3432 - mean_absolute_error: 0.4698 - val_loss: 0.1491 - val_mean_absolute_error: 0.3200\n",
      "Epoch 13/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.3366 - mean_absolute_error: 0.4648 - val_loss: 0.1233 - val_mean_absolute_error: 0.2854\n",
      "Epoch 14/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.3277 - mean_absolute_error: 0.4538 - val_loss: 0.1213 - val_mean_absolute_error: 0.2854\n",
      "Epoch 15/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.2812 - mean_absolute_error: 0.4155 - val_loss: 0.1058 - val_mean_absolute_error: 0.2654\n",
      "Epoch 16/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.2857 - mean_absolute_error: 0.4259 - val_loss: 0.1031 - val_mean_absolute_error: 0.2617\n",
      "Epoch 17/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.2978 - mean_absolute_error: 0.4339 - val_loss: 0.0925 - val_mean_absolute_error: 0.2465\n",
      "Epoch 18/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.2589 - mean_absolute_error: 0.4057 - val_loss: 0.0829 - val_mean_absolute_error: 0.2332\n",
      "Epoch 19/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.2646 - mean_absolute_error: 0.4108 - val_loss: 0.0756 - val_mean_absolute_error: 0.2217\n",
      "Epoch 20/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.2416 - mean_absolute_error: 0.3854 - val_loss: 0.0807 - val_mean_absolute_error: 0.2308\n",
      "Epoch 21/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.2619 - mean_absolute_error: 0.4059 - val_loss: 0.0806 - val_mean_absolute_error: 0.2315\n",
      "Epoch 22/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.2502 - mean_absolute_error: 0.3933 - val_loss: 0.0804 - val_mean_absolute_error: 0.2308\n",
      "Epoch 23/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.2424 - mean_absolute_error: 0.3847 - val_loss: 0.0748 - val_mean_absolute_error: 0.2215\n",
      "Epoch 24/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.2332 - mean_absolute_error: 0.3796 - val_loss: 0.0721 - val_mean_absolute_error: 0.2169\n",
      "Epoch 25/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.2334 - mean_absolute_error: 0.3791 - val_loss: 0.0706 - val_mean_absolute_error: 0.2131\n",
      "Epoch 26/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.2431 - mean_absolute_error: 0.3899 - val_loss: 0.0760 - val_mean_absolute_error: 0.2242\n",
      "Epoch 27/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.2242 - mean_absolute_error: 0.3755 - val_loss: 0.0645 - val_mean_absolute_error: 0.2024\n",
      "Epoch 28/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.2262 - mean_absolute_error: 0.3748 - val_loss: 0.0697 - val_mean_absolute_error: 0.2148\n",
      "Epoch 29/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.2218 - mean_absolute_error: 0.3726 - val_loss: 0.0734 - val_mean_absolute_error: 0.2221\n",
      "Epoch 30/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.2259 - mean_absolute_error: 0.3796 - val_loss: 0.0646 - val_mean_absolute_error: 0.2077\n",
      "Epoch 31/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.2186 - mean_absolute_error: 0.3685 - val_loss: 0.0604 - val_mean_absolute_error: 0.1995\n",
      "Epoch 32/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.2159 - mean_absolute_error: 0.3615 - val_loss: 0.0592 - val_mean_absolute_error: 0.1962\n",
      "Epoch 33/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.2193 - mean_absolute_error: 0.3696 - val_loss: 0.0590 - val_mean_absolute_error: 0.1933\n",
      "Epoch 34/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.2214 - mean_absolute_error: 0.3695 - val_loss: 0.0590 - val_mean_absolute_error: 0.1927\n",
      "Epoch 35/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.2110 - mean_absolute_error: 0.3659 - val_loss: 0.0587 - val_mean_absolute_error: 0.1912\n",
      "Epoch 36/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.2062 - mean_absolute_error: 0.3646 - val_loss: 0.0582 - val_mean_absolute_error: 0.1930\n",
      "Epoch 37/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.2001 - mean_absolute_error: 0.3543 - val_loss: 0.0592 - val_mean_absolute_error: 0.1958\n",
      "Epoch 38/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.2269 - mean_absolute_error: 0.3761 - val_loss: 0.0585 - val_mean_absolute_error: 0.1947\n",
      "Epoch 39/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.2075 - mean_absolute_error: 0.3584 - val_loss: 0.0602 - val_mean_absolute_error: 0.1960\n",
      "Epoch 40/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.1944 - mean_absolute_error: 0.3496 - val_loss: 0.0586 - val_mean_absolute_error: 0.1940\n",
      "Epoch 41/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.1991 - mean_absolute_error: 0.3505 - val_loss: 0.0590 - val_mean_absolute_error: 0.1937\n",
      "Epoch 42/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.1993 - mean_absolute_error: 0.3502 - val_loss: 0.0601 - val_mean_absolute_error: 0.1975\n",
      "Epoch 43/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.1979 - mean_absolute_error: 0.3561 - val_loss: 0.0568 - val_mean_absolute_error: 0.1890\n",
      "Epoch 44/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.2088 - mean_absolute_error: 0.3653 - val_loss: 0.0594 - val_mean_absolute_error: 0.1959\n",
      "Epoch 45/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.2039 - mean_absolute_error: 0.3588 - val_loss: 0.0576 - val_mean_absolute_error: 0.1929\n",
      "Epoch 46/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.2085 - mean_absolute_error: 0.3595 - val_loss: 0.0554 - val_mean_absolute_error: 0.1893\n",
      "Epoch 47/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.1833 - mean_absolute_error: 0.3331 - val_loss: 0.0560 - val_mean_absolute_error: 0.1927\n",
      "Epoch 48/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.1875 - mean_absolute_error: 0.3445 - val_loss: 0.0530 - val_mean_absolute_error: 0.1866\n",
      "Epoch 49/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.2025 - mean_absolute_error: 0.3538 - val_loss: 0.0567 - val_mean_absolute_error: 0.1932\n",
      "Epoch 50/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.1979 - mean_absolute_error: 0.3506 - val_loss: 0.0582 - val_mean_absolute_error: 0.1952\n",
      "Test Loss: 0.05737633258104324\n",
      "Test Mean Absolute Error: 0.18828263878822327\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.3),  \n",
    "    BatchNormalization(),  \n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    BatchNormalization(),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    BatchNormalization(),\n",
    "    Dense(1) \n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=16, validation_split=0.2, verbose=1)\n",
    "\n",
    "test_loss, test_mae = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Mean Absolute Error:\", test_mae)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
